{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG应用的评估\n",
    "\n",
    "### 如何评估一个RAG应用\n",
    "\n",
    "RAG（检索增强生成）是一种结合了信息检索和自然语言生成的技术，广泛应用于知识问答、客户服务等领域。要实现高质量的RAG应用，必须对其进行全面的评估和优化。本文将从以下几个方面展开介绍：如何评估RAG应用，如何评估及优化检索模块，以及如何评估及优化生成模块。\n",
    "\n",
    "评估RAG应用需要综合考虑：\n",
    "\n",
    "- **检索性能** ：检索的准确率和召回率\n",
    "\n",
    "检索模块决定了从知识库中找到的文档质量，是RAG应用的基础。主要评估指标包括：\n",
    "\n",
    "- 准确率（Precision）：检索结果中相关文档的比例。\n",
    "\n",
    "- 召回率（Recall）：所有相关文档中被检索出的比例。\n",
    "\n",
    "- F1值：准确率和召回率的调和平均值。\n",
    "\n",
    "- **生成质量** ：回答的准确性、流畅度和相关性\n",
    "\n",
    "- 准确性：回答是否正确。\n",
    "\n",
    "- 流畅性：语言是否自然。\n",
    "\n",
    "- 相关性：回答是否与问题紧密相关。\n",
    "\n",
    "- **用户体验** ：响应速度、交互友好性\n",
    "\n",
    "用户体验评估主要关注应用的交互友好性，包括：\n",
    "\n",
    "- 响应速度：回答的生成时间。\n",
    "\n",
    "- 交互性：系统界面和交互设计是否直观。\n",
    "\n",
    "- 稳定性：系统是否可靠，无明显错误。\n",
    "\n",
    "---\n",
    "\n",
    "### 评估及优化检索模块\n",
    "\n",
    " **评估**  **检索模块的方法** ：\n",
    "\n",
    "- **指标评估** ：使用准确率、召回率、F1值等指标\n",
    "\n",
    "评估检索模块时，常用以下指标：\n",
    "\n",
    "- 准确率：衡量检索结果的相关性。\n",
    "\n",
    "- 召回率：衡量检索结果的覆盖范围。\n",
    "\n",
    "- F1值：综合考虑准确率和召回率。\n",
    "\n",
    " **评估检索模块** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suntao/Documents/GitHub/camel/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-31 21:55:33,009 - unstructured - WARNING - libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "from camel.embeddings import SentenceTransformerEncoder\n",
    "from camel.retrievers import VectorRetriever\n",
    "from camel.storages.vectordb_storages import QdrantStorage\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "# 初始化嵌入模型\n",
    "embedding_model = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')\n",
    "\n",
    "# 初始化向量存储\n",
    "vector_storage = QdrantStorage(\n",
    "    vector_dim=embedding_model.get_output_dim(),\n",
    "    collection=\"test_collection\",\n",
    "    path=\"test_storage\",\n",
    "    collection_name=\"CAMEL AI 文档\"\n",
    ")\n",
    "\n",
    "# 初始化检索器\n",
    "vr = VectorRetriever(embedding_model=embedding_model, storage=vector_storage)\n",
    "\n",
    "input_path = \"example_document.md\"\n",
    "\n",
    "# 处理文档并构建向量数据库\n",
    "vr.process(content=input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里可以使用我们用LLM生成的一个示例md文档作为我们要检索的文档，使用本地的embedding模型和向量检索器。\n",
    "\n",
    "\n",
    "在这里我们设置一些问题和我们预期的标准答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    {\n",
    "        \"query\": \"什么是CAMEL AI？\",\n",
    "        \"expected_answers\": [\"CAMEL AI 是一个开源的、社区驱动的AI框架。\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"如何开始使用CAMEL AI？\",\n",
    "        \"expected_answers\": [\"首先安装框架：`pip install camel-ai`，然后引入必要的模块。\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"CAMEL AI 的主要特点是什么？\",\n",
    "        \"expected_answers\": [\"模块化设计、易用性和扩展性。\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后，我们定义我们的评估指标，我们计算检索出的结果和我们预期结果之间的余弦相似度，并且认为超过一定范围时检索的结果是符合预期的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估指标\n",
    "def calculate_precision(retrieved, relevant, threshold=0.5):\n",
    "    \"\"\"计算精确率（Precision），当相似度超过阈值时认为是正确的\"\"\"\n",
    "    correct = 0\n",
    "    for r in retrieved:\n",
    "        for rel in relevant:\n",
    "            similarity = compute_similarity(rel, r)\n",
    "            if similarity >= threshold:\n",
    "                correct += 1\n",
    "                break\n",
    "    return correct / len(retrieved) if retrieved else 0\n",
    "\n",
    "def calculate_recall(retrieved, relevant, threshold=0.5):\n",
    "    \"\"\"计算召回率（Recall），当相似度超过阈值时认为是正确的\"\"\"\n",
    "    correct = 0\n",
    "    for rel in relevant:\n",
    "        for r in retrieved:\n",
    "            similarity = compute_similarity(rel, r)\n",
    "            if similarity >= threshold:\n",
    "                correct += 1\n",
    "                break\n",
    "    return correct / len(relevant) if relevant else 0\n",
    "\n",
    "def calculate_f1(precision, recall):\n",
    "    \"\"\"计算F1值\"\"\"\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "def compute_similarity(expected, retrieved):\n",
    "    \"\"\"计算预期答案与检索结果的相似度\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform([expected, retrieved])\n",
    "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
    "    return similarity_matrix[0, 1]\n",
    "\n",
    "def evaluate_retrieval(query, expected_answers, threshold=0.5, top_k=1):\n",
    "    \"\"\"评估单个查询的检索质量\"\"\"\n",
    "    results = vr.query(query=query, top_k=top_k)\n",
    "    retrieved_texts = [result[\"text\"] for result in results]\n",
    "    \n",
    "    # 计算精确率、召回率和F1值\n",
    "    precision = calculate_precision(retrieved_texts, expected_answers, threshold)\n",
    "    recall = calculate_recall(retrieved_texts, expected_answers, threshold)\n",
    "    f1 = calculate_f1(precision, recall)\n",
    "    \n",
    "    # 计算平均相似度\n",
    "    similarities = []\n",
    "    for expected, retrieved in zip(expected_answers, retrieved_texts):\n",
    "        similarities.append(compute_similarity(expected, retrieved))\n",
    "    avg_similarity = np.mean(similarities) if similarities else 0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"avg_similarity\": avg_similarity,\n",
    "        \"retrieved_texts\": retrieved_texts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们执行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 什么是CAMEL AI？\n",
      "Expected Answers: ['CAMEL AI 是一个开源的、社区驱动的AI框架。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。\\n\\n主要特点\\n\\n模块化设计：用户可以根据需求选择性地加载不同的功能模块。\\n\\n易用性：提供了简单易用的API接口，降低了开发门槛。\\n\\n拓展性：支持多种模型和后端服务，方便用户根据需求进行扩展。\\n\\n常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.5722\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Query: 如何开始使用CAMEL AI？\n",
      "Expected Answers: ['首先安装框架：`pip install camel-ai`，然后引入必要的模块。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。\\n\\n主要特点\\n\\n模块化设计：用户可以根据需求选择性地加载不同的功能模块。\\n\\n易用性：提供了简单易用的API接口，降低了开发门槛。\\n\\n拓展性：支持多种模型和后端服务，方便用户根据需求进行扩展。\\n\\n常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Average Similarity: 0.4752\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Query: CAMEL AI 的主要特点是什么？\n",
      "Expected Answers: ['模块化设计、易用性和扩展性。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。\\n\\n主要特点\\n\\n模块化设计：用户可以根据需求选择性地加载不同的功能模块。\\n\\n易用性：提供了简单易用的API接口，降低了开发门槛。\\n\\n拓展性：支持多种模型和后端服务，方便用户根据需求进行扩展。\\n\\n常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Average Similarity: 0.0502\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "整体评估结果:\n",
      "Average Precision: 0.3333\n",
      "Average Recall: 0.3333\n",
      "Average F1 Score: 0.3333\n",
      "Average Similarity: 0.3659\n"
     ]
    }
   ],
   "source": [
    "# 执行评估\n",
    "evaluation_results = []\n",
    "for test_case in test_queries:\n",
    "    query = test_case[\"query\"]\n",
    "    expected_answers = test_case[\"expected_answers\"]\n",
    "    \n",
    "    evaluation = evaluate_retrieval(query, expected_answers)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        \"query\": query,\n",
    "        \"expected_answers\": expected_answers,\n",
    "        \"evaluation\": evaluation\n",
    "    })\n",
    "    \n",
    "    # 打印详细结果\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Expected Answers: {expected_answers}\")\n",
    "    print(f\"Retrieved Results: {evaluation['retrieved_texts']}\")\n",
    "    print(f\"Precision: {evaluation['precision']:.4f}\")\n",
    "    print(f\"Recall: {evaluation['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {evaluation['f1']:.4f}\")\n",
    "    print(f\"Average Similarity: {evaluation['avg_similarity']:.4f}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "# 计算整体评估结果\n",
    "total_precision = sum(result[\"evaluation\"][\"precision\"] for result in evaluation_results) / len(evaluation_results)\n",
    "total_recall = sum(result[\"evaluation\"][\"recall\"] for result in evaluation_results) / len(evaluation_results)\n",
    "total_f1 = sum(result[\"evaluation\"][\"f1\"] for result in evaluation_results) / len(evaluation_results)\n",
    "total_similarity = sum(result[\"evaluation\"][\"avg_similarity\"] for result in evaluation_results) / len(evaluation_results)\n",
    "\n",
    "print(\"\\n整体评估结果:\")\n",
    "print(f\"Average Precision: {total_precision:.4f}\")\n",
    "print(f\"Average Recall: {total_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {total_f1:.4f}\")\n",
    "print(f\"Average Similarity: {total_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过以上的步骤，我们可以完成一个简单检索模块的评估。下面我们来看一下如何优化我们的检索模块。\n",
    "\n",
    "首先我们会发现在上面第三条检索的结果其实是涵盖了我们的预期结果的，但是由于我们使用的是基于TF-IDF的余弦相似度。导致了其得分较低\n",
    "\n",
    "首先，我们简单介绍一下TF-IDF的基本原理和它在相似度计算中的应用。TF-IDF（词频-逆向文件频率）是一种用于信息检索和文本挖掘的常用加权技术，用于评估一个词在文档中的重要程度。其核心思想是：如果某个词在一篇文档中出现的频率高，并且在其他文档中很少出现，则认为该词具有很好的类别区分能力。\n",
    "\n",
    "这种方法在我们第三条结果出现的问题是：\n",
    "\n",
    " **忽略语义信息** ：TF-IDF基于词频统计，无法捕捉词语之间的语义关系。例如，“汽车”和“车辆”在语义上是相近的，但TF-IDF会将其视为完全不同的词。\n",
    "\n",
    "而且预期的结果和检索到的结果字数差距较大，导致两条结果的在基于TF-IDF的余弦相似度下相差较大。这里我们可以尝试使用Embedding模型来将结果转成向量之后再计算余弦相似度。它的特点如下：\n",
    "\n",
    " **优点** ：精准捕捉语义和语境。 **缺点** ：计算资源消耗大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后，我们定义我们的评估指标，我们计算检索出的结果和我们预期结果之间的余弦相似度，并且认为超过一定范围时检索的结果是符合预期的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们将原有的compute_similarity函数替换一下\n",
    "\n",
    "def compute_similarity(expected, retrieved):\n",
    "     \"\"\"计算预期答案与检索结果的相似度\"\"\"\n",
    "     vectorizer = TfidfVectorizer()\n",
    "     tfidf = vectorizer.fit_transform([expected, retrieved])\n",
    "     similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
    "     return similarity_matrix[0, 1]\n",
    "\n",
    "def compute_similarity(expected, retrieved):\n",
    "    \"\"\"计算预期答案与检索结果的相似度\"\"\"\n",
    "    embeddings = embedding_model.embed_list([expected, retrieved])\n",
    "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 什么是CAMEL AI？\n",
      "Expected Answers: ['CAMEL AI 是一个开源的、社区驱动的AI框架。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。\\n\\n主要特点\\n\\n模块化设计：用户可以根据需求选择性地加载不同的功能模块。\\n\\n易用性：提供了简单易用的API接口，降低了开发门槛。\\n\\n拓展性：支持多种模型和后端服务，方便用户根据需求进行扩展。\\n\\n常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.9024\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Query: 如何开始使用CAMEL AI？\n",
      "Expected Answers: ['首先安装框架：`pip install camel-ai`，然后引入必要的模块。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。\\n\\n主要特点\\n\\n模块化设计：用户可以根据需求选择性地加载不同的功能模块。\\n\\n易用性：提供了简单易用的API接口，降低了开发门槛。\\n\\n拓展性：支持多种模型和后端服务，方便用户根据需求进行扩展。\\n\\n常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.9148\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Query: CAMEL AI 的主要特点是什么？\n",
      "Expected Answers: ['模块化设计、易用性和扩展性。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。\\n\\n主要特点\\n\\n模块化设计：用户可以根据需求选择性地加载不同的功能模块。\\n\\n易用性：提供了简单易用的API接口，降低了开发门槛。\\n\\n拓展性：支持多种模型和后端服务，方便用户根据需求进行扩展。\\n\\n常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.8000\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 执行评估\n",
    "evaluation_results = []\n",
    "for test_case in test_queries:\n",
    "    query = test_case[\"query\"]\n",
    "    expected_answers = test_case[\"expected_answers\"]\n",
    "    \n",
    "    evaluation = evaluate_retrieval(query, expected_answers)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        \"query\": query,\n",
    "        \"expected_answers\": expected_answers,\n",
    "        \"evaluation\": evaluation\n",
    "    })\n",
    "    \n",
    "    # 打印详细结果\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Expected Answers: {expected_answers}\")\n",
    "    print(f\"Retrieved Results: {evaluation['retrieved_texts']}\")\n",
    "    print(f\"Precision: {evaluation['precision']:.4f}\")\n",
    "    print(f\"Recall: {evaluation['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {evaluation['f1']:.4f}\")\n",
    "    print(f\"Average Similarity: {evaluation['avg_similarity']:.4f}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，这次评估的结果更加符合我们人类的标准。\n",
    "\n",
    "另外我们可以发现，我们每次检索到的内容其实完全一样，这是因为VectorRetriever会默认将文档按照500字为间隔来划分，我们将这里我们可以调整一下chunk的大小，之后重新划分文档："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-31 21:57:11,165 - unstructured - WARNING - libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "# 初始化向量存储\n",
    "vector_storage = QdrantStorage(\n",
    "    vector_dim=embedding_model.get_output_dim(),\n",
    "    collection=\"test_collection\",\n",
    "    path=\"test_storage\",\n",
    "    collection_name=\"CAMEL AI 文档\"\n",
    ")\n",
    "\n",
    "# 初始化检索器\n",
    "vr = VectorRetriever(embedding_model=embedding_model, storage=vector_storage)\n",
    "\n",
    "vr.process(\n",
    "    content=\"example_document.md\",\n",
    "    max_characters=100,\n",
    "    should_chunk=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后再次检索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 什么是CAMEL AI？\n",
      "Expected Answers: ['CAMEL AI 是一个开源的、社区驱动的AI框架。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.9584\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Query: 如何开始使用CAMEL AI？\n",
      "Expected Answers: ['首先安装框架：`pip install camel-ai`，然后引入必要的模块。']\n",
      "Retrieved Results: ['常见问题\\n\\n如何开始使用CAMEL AI？\\n\\n首先安装框架：pip install camel-ai\\n\\n引入必要的模块：from camel import *\\n\\n参考官方文档：CAMEL AI官方文档']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.9604\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Query: CAMEL AI 的主要特点是什么？\n",
      "Expected Answers: ['模块化设计、易用性和扩展性。']\n",
      "Retrieved Results: ['CAMEL AI 介绍\\n\\nCAMEL AI 是一个开源的、社区驱动的AI框架，旨在简化AI应用的开发和部署。该框架提供了多种功能模块，包括数据加载、特征工程、模型训练和部署等。']\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Average Similarity: 0.8103\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "整体评估结果:\n",
      "Average Precision: 1.0000\n",
      "Average Recall: 1.0000\n",
      "Average F1 Score: 1.0000\n",
      "Average Similarity: 0.9097\n"
     ]
    }
   ],
   "source": [
    "# 执行评估\n",
    "evaluation_results = []\n",
    "for test_case in test_queries:\n",
    "    query = test_case[\"query\"]\n",
    "    expected_answers = test_case[\"expected_answers\"]\n",
    "    \n",
    "    evaluation = evaluate_retrieval(query, expected_answers)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        \"query\": query,\n",
    "        \"expected_answers\": expected_answers,\n",
    "        \"evaluation\": evaluation\n",
    "    })\n",
    "    \n",
    "    # 打印详细结果\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Expected Answers: {expected_answers}\")\n",
    "    print(f\"Retrieved Results: {evaluation['retrieved_texts']}\")\n",
    "    print(f\"Precision: {evaluation['precision']:.4f}\")\n",
    "    print(f\"Recall: {evaluation['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {evaluation['f1']:.4f}\")\n",
    "    print(f\"Average Similarity: {evaluation['avg_similarity']:.4f}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "# 计算整体评估结果\n",
    "total_precision = sum(result[\"evaluation\"][\"precision\"] for result in evaluation_results) / len(evaluation_results)\n",
    "total_recall = sum(result[\"evaluation\"][\"recall\"] for result in evaluation_results) / len(evaluation_results)\n",
    "total_f1 = sum(result[\"evaluation\"][\"f1\"] for result in evaluation_results) / len(evaluation_results)\n",
    "total_similarity = sum(result[\"evaluation\"][\"avg_similarity\"] for result in evaluation_results) / len(evaluation_results)\n",
    "\n",
    "print(\"\\n整体评估结果:\")\n",
    "print(f\"Average Precision: {total_precision:.4f}\")\n",
    "print(f\"Average Recall: {total_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {total_f1:.4f}\")\n",
    "print(f\"Average Similarity: {total_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现效果又更近了一步。\n",
    "\n",
    "更多的调整方向可以参考以下几点：\n",
    "\n",
    "- **参数调整** ：优化嵌入模型和检索算法的参数\n",
    "\n",
    "优化嵌入模型和检索算法的参数，例如：\n",
    "\n",
    "- 调整嵌入向量的维度。\n",
    "\n",
    "- 优化检索的相似度计算方法（如欧几里得距离、余弦相似度）。\n",
    "\n",
    "- 在自身场景下微调嵌入模型通过效果是明显的\n",
    "\n",
    "- **数据增强** ：扩充知识库，提高覆盖面\n",
    "\n",
    "通过扩充知识库提高覆盖面，例如：\n",
    "\n",
    "- 添加更多高质量的知识数据。\n",
    "\n",
    "- 利用数据增强技术生成多样化的知识表达。\n",
    "\n",
    "- **检索策略优化** ：\n",
    "\n",
    "- 分阶段检索\n",
    "\n",
    "- 混合检索(如TF-IDF + 语义模型)\n",
    "\n",
    "- 实时反优化\n",
    "\n",
    "### 评估及优化生成模块\n",
    "\n",
    "优化生成模块的方法：\n",
    "\n",
    "- **质量评估** ：使用BLEU、ROUGE等自动指标和人工评估\n",
    "\n",
    "生成模块的评估可以分为自动评估和人工评估：\n",
    "\n",
    "- 自动评估：使用BLEU、ROUGE等指标衡量生成文本的质量。\n",
    "\n",
    "- 人工评估：通过专家或用户打分，评估文本的准确性、流畅性和相关性。\n",
    "\n",
    "- **上下文增强** ：提供更丰富的上下文信息\n",
    "\n",
    "- 为生成模型提供更丰富的上下文信息，例如问题背景或用户历史记录。\n",
    "\n",
    "代码示例：以下展示了如何评估生成模块的回答质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.67\n",
      "ROUGE-L: 0.67\n",
      "BLEU Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# 示例数据\n",
    "reference = \"RAG combines retrieval and generation for QA.\"\n",
    "generated = \"RAG integrates retrieval and generation for question answering.\"\n",
    "\n",
    "# 使用ROUGE评估\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference, generated)\n",
    "\n",
    "# 使用BLEU评估\n",
    "reference_tokens = word_tokenize(reference)\n",
    "generated_tokens = word_tokenize(generated)\n",
    "bleu_score = sentence_bleu([reference_tokens], generated_tokens)\n",
    "\n",
    "print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.2f}\")\n",
    "print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.2f}\")\n",
    "print(f\"BLEU Score: {bleu_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
