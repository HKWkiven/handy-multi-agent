## 4.1 RAG的组件介绍

### 4.1.1 RAG简介

要理解生成式AI的最新进展，可以想象一个法庭场景。

法官基于对法律的一般理解听取并裁定案件。有时，一些案件——比如医疗事故诉讼或劳动争议——需要特殊的专业知识，于是法官会派书记员去法律图书馆查找先例和具体的法律案例以供引用。

像优秀的法官一样，大型语言模型（LLM）能够回答各种人类问题。但如果需要提供权威答案并引用具体来源，模型需要一个助手来进行研究。

AI的“法庭书记员”就是一种被称为检索增强生成（RAG，Retrieval-Augmented Generation）的技术。

**"RAG"这个名字的由来**

2020年首次提出这一术语的论文主作者帕特里克·刘易斯（Patrick Lewis）对现在这一流行技术的不起眼缩写表示歉意。他认为这一方法已代表生成式AI的未来，相关研究已覆盖数百篇论文和众多商业服务。

"如果早知道我们的研究会被如此广泛应用，我们一定会更认真地起名字"刘易斯在一次新加坡区域数据库开发者会议的采访中说道。

"我们原本计划为这个技术取一个更好听的名字，但最终写论文时，大家都没有提出更好的想法。"刘易斯目前领导AI初创公司Cohere的一支RAG团队。

**什么是检索增强生成（RAG）？**

检索增强生成是一种通过从外部资源获取事实来提高生成式AI模型准确性和可靠性的技术。

换句话说，它弥补了LLM工作中的一个空白。从底层来看，LLM是神经网络，其能力通常通过参数数量来衡量。LLM的参数本质上代表了人类使用单词构造句子的通用模式。

这种深度理解（有时称为参数化知识）使得LLM能够以极快的速度对一般性提示做出回应。然而，当用户需要深入探讨某一当前或特定话题时，LLM可能力不从心。

**内部与外部资源的结合**

刘易斯及其同事开发了RAG技术，将生成式AI服务与外部资源相连，特别是那些富含最新技术细节的资源。

他们与前Facebook AI研究团队（现为Meta AI）、伦敦大学学院（UCL）和纽约大学的共同作者在论文中将RAG称为“一种通用的微调方法”，因为几乎任何LLM都可以使用它连接几乎任何外部资源。

**建立用户信任**

检索增强生成为模型提供了可引用的来源，就像研究论文中的脚注，用户可以查证这些信息。这有助于建立信任。

此外，这项技术还可以帮助模型澄清用户查询中的歧义，并减少模型“猜错”的可能性——这种现象有时被称为“幻觉”（hallucination）。

RAG的另一个显著优势在于其实现相对简单。刘易斯和论文的三位共同作者在博客中提到，开发者可以用少至五行代码来实现这一过程。这使得RAG比用额外数据集重新训练模型更快捷、更经济。此外，它还支持用户即时更换新的信息源。

**RAG的应用**

通过检索增强生成，用户可以与数据存储库进行交互，从而开辟新的应用体验。这意味着RAG的潜在应用可以是可用数据集数量的多倍。

例如，一个结合了医学索引的生成式AI模型可以成为医生或护士的得力助手。金融分析师可以借助与市场数据相连的助手提高工作效率。

事实上，几乎任何企业都可以将其技术手册、政策手册、视频或日志转化为知识库，以提升LLM的能力。这些资源可以支持诸如客户服务、员工培训和开发者生产力等用例。

正因如此，包括AWS、IBM、Glean、Google、Microsoft、NVIDIA、Oracle和Pinecone在内的公司正在广泛采用RAG技术。

在CAMEL框架中，RAG被用于构建智能问答系统、对话Agent等应用，充分利用了框架的模块化设计和强大的处理能力。

### 4.1.2 Loaders

**基本概念**

Loaders是CAMEL框架中用于数据加载和预处理的模块。简而言之就是在 **CAMEL 框架** 中，引入了两个 IO 模块：**Base IO** 和 **Unstructured IO**，用于处理多种文件类型以及非结构化数据的处理。此外，还新增了四种数据读取器：**Apify Reader**、**Chunkr Reader**、**Firecrawl Reader** 和 **Jina\_url Reader**，这些读取器能够从外部获取数据，从而提升数据集成与分析的能力。

**Base IO**

**Base IO 模块**专注于与文件相关的基础输入/输出操作，提供了表示、读取和处理多种文件格式的功能。

在实践环节中，该模块旨在读取各种格式的文件，提取其内容，并将其表示为 **File 对象**，每个对象都针对特定的文件类型进行了专门设计以便高效处理。

```python
from io import BytesIO
from camel.loaders import create_file_from_raw_bytes

# 读取pdf文件
with open("test.pdf", "rb") as file:
    file_content = file.read()

# 使用create_file函数根据文件扩展名创建对象
file_obj = create_file_from_raw_bytes(file_content, "test.pdf")

# 获取File对象的内容
print(file_obj.docs[0]["page_content"])
```

***

**Unstructured IO**

**Unstructured IO 模块&#x20;**&#x4E13;注于非结构化数据的处理、解析和加工。它提供了以下工具和功能：解析文件或URL、清洗数据、提取特定信息、为不同平台准备数据元素以及对数据进行分块处理。该模块的核心在于其高级ETL（提取、转换、加载）能力，可以对非结构化数据进行操作，使其适用于诸如 **检索增强生成（RAG）**&#x7B49;多种应用场景。

要开始使用 **Unstructured IO 模块**，首先需要导入模块并初始化其实例。初始化后，可以利用该模块执行多种功能，例如解析、清洗、提取数据，并与云服务（如 AWS S3 和 Azure）集成。以下是一个基本指南，帮助您快速上手：

**使用 `parse_file_or_url` 方法可以从文件或 URL 中加载并解析非结构化数据。以下是如何利用此方法的指导示例：**

```python
from camel.loaders import UnstructuredIO
uio = UnstructuredIO()
#设置一个url示例
example_url = ("https://hub.baai.ac.cn/view/41733")
elements = uio.parse_file_or_url(example_url)
print(("\n\n".join([str(el) for el in elements])))
```

```python
>>> 
CAMEL-AI团队参与发表Nature子刊啦!聚焦LLM如何重塑未来医疗 ~

Smart Medicine

AI system

AI

DrugAI
                  2024-12-11 00:50 分享

DrugAI

帖子数：772

个人主页

以下文章来源于mp.weixin.qq.com

未来医疗是否可能由人工智能主导？CAMEL团队参与撰写的《Nature Machine Intelligence》最新Comment文章，带我们展望了基于大语言模型（LLM）的智能体系统在医疗领域的应用前景。这些“智能队友”不仅能够协同诊断、优化流程，还能实现个性化健康管理和精准治疗。从自动化病历记录到多学科智能协作，这项技术正逐步改变传统医疗模式，为未来医疗提供了全新的可能性和解决方案。

LLM驱动的智能体系统

LLM驱动的智能体系统是一种基于大语言模型（LLM）的增强型人工智能系统，通过集成多个模块实现从感知到行动的全流程功能。简单来说，它是一种具备感知、思考、决策和执行能力的“数字智能体”。LLM智能体主要结合了以下关键模块：
...

登录 后发表评论～

沙发等你来抢
Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...
```

**利用 `clean_text_data` 进行多文本数据清洗**

```python
# 设置示例脏文本
example_dirty_text = ("\x93Some dirty text â€™ with extra spaces and – dashes.一些包含额外空格和破折号的脏文本â€™。")
# 设置清理选项   
options = [
    ('replace_unicode_quotes', {}),  # 替换Unicode引号
    ('clean_dashes', {}),           # 清理破折号
    ('clean_non_ascii_chars', {}),  # 清理非ASCII字符
    ('clean_extra_whitespace', {}), # 清理多余空白
]
cleaned_text = uio.clean_text_data(text=example_dirty_text,
                                   clean_options=options)
print(cleaned_text)
```

```plain&#x20;text
>>> 
Some dirty text with extra spaces and dashes.
```

**目前支持的清理操作**:

* replace\_unicode\_quotes: 将Unicode引号替换为标准引号

* clean\_dashes: 清理破折号，统一格式

* clean\_non\_ascii\_chars: 清理非ASCII字符

* clean\_extra\_whitespace: 清理多余空白

* clean\_bullets: 清理项目符号

* clean\_ordered\_bullets: 清理有序列表符号

* clean\_postfix: 清理后缀

* clean\_prefix: 清理前缀

* clean\_trailing\_punctuation: 清理尾部标点

* group\_broken\_paragraphs: 合并断开的段落

* remove\_punctuation: 移除标点符号

* bytes\_string\_to\_string: 将字节字符串转换为普通字符串

* translate\_text: 翻译文本



**利用 `extract_data_from_text` 进行文本提取操作，下面是一个抽取文本中邮件地址的范例。**

```python
# 设置示例文本用于提取
example_email_text = "你可以通过example@email.com联系我"
extracted_text = uio.extract_data_from_text(text=example_email_text,extract_type="extract_email_address")
print(extracted_text)
```

```plain&#x20;text
>>> ['example@email.com']
```

`extract_data_from_text`同样有多种使用方法，更具体的使用方法可以看源码的相关注释。



**使用 `chunk_elements` 方法对内容进行分块处理**

```python
from camel.loaders import UnstructuredIO
uio = UnstructuredIO()
#设置一个url示例
example_url = ("https://hub.baai.ac.cn/view/41733")
elements = uio.parse_file_or_url(example_url)

chunks = uio.chunk_elements(elements=elements,chunk_type="chunk_by_title")

for chunk in chunks:
    print(chunk)
    print("\n" + "-" * 80)
```

```plain&#x20;text
>>> The Empire State Building was lit in green and white to celebrate the Philadelphia Eagles’ victory in the NFC Championship game on Sunday – a decision that’s sparked a bit of a backlash in the Big Apple.

>>>  The Eagles advanced to the Super Bowl for the first time since 2018 after defeating the San Francisco 49ers 31-7, and the Empire State Building later tweeted how it was marking the occasion.

>>>  --------------------------------------------------------------------------------
>>>  Fly @Eagles Fly! We’re going Green and White in honor of the Eagles NFC Championship Victory. pic.twitter.com/RNiwbCIkt7— Empire State Building (@EmpireStateBldg)
```

使用 `stage_elements` 方法进行元素分阶段处理

```plain&#x20;text
staged_element = uio.stage_elements(elements=elements,stage_type="stage_for_baseplate")
print(staged_element)
```

```plain&#x20;text
>>> {'rows': [{'data': {'type': 'UncategorizedText', 'element_id': 'e78902d05b0cb1e4c38fc7a79db450d5', 'text': 'CNN\n        \xa0—'}, 'metadata': {'filetype': 'text/html', 'languages': ['eng'], 'page_number': 1, 'url': 'https://www.cnn.com/2023/01/30/sport/empire-state-building-green-philadelphia-eagles-spt-intl/index.html', 'emphasized_text_contents': ['CNN'], 'emphasized_text_tags': ['span']}}, ...
```

以下是使用 **Unstructured IO 模块**的基础指南。想要了解更多高级用法，请参考具体方法的文档以及相关资源。 [Unstructured IO Documentation](https://unstructured-io.github.io/unstructured/)。[其他**Loader**的介绍可以参考附录](https://fmhw1n4zpn.feishu.cn/docx/AF4XdOZpIo6TOaxzDK8cxInNnCe#share-ScDDdqchMo2cz0xdN2HcD1k0nkb)。

***

### 4.1.3 Embddings

**基本概念**

为不同类型的数据（文本、图像、视频）创建嵌入的过程，是将这些输入转化为机器能够理解和高效处理的数值形式。每种嵌入都专注于捕获其对应数据类型的核心特征。以下是对主要数据类型嵌入的简要说明：

**文本嵌入**

文本嵌入（Text Embeddings）将文本数据转换为数值向量，每个向量代表文本的语义含义，使我们能够基于意义而非文本的原始形式处理和比较文本。通过这种方式，机器可以捕获语言中的上下文和细微差别。

**嵌入技术**

1. **OpenAI Embedding**:

   * 使用大规模语言模型（LLM）生成嵌入，能够理解语言中的复杂语境和语义细节。

   * 例如，`text-embedding-3-small` 模型生成 1536 维嵌入向量。

2. **SentenceTransformerEncoder**:

   * 专为生成句子级别的嵌入设计，通常基于 BERT 等模型。

   * 强调对句子语义的捕获，适合文本比较或语义搜索任务。

3. **OpenAICompatibleEmbedding**

类似于**OpenAI Embedding**



**示例：语义比较**

**句子 1**: “A young boy is playing soccer in a park.”
**句子 2**: “A child is kicking a football on a playground.”

尽管两句话用词不同，但它们表达的语义非常相似。

&#x20;文本嵌入模型会将这些句子转换为高维向量，例如 1536 维。如果我们比较这两个向量，计算出的相似度值（如余弦相似度）会较高，表明它们具有相近的语义。

***

**语义处理的意义**

1. **语义相似性**: 嵌入捕获了“孩子在户外踢球”的共同概念，而不是简单地依赖词语的字面匹配。

2. **应用场景**:&#x20;

   * **信息检索**: 根据语义找到相关内容，而非精确关键词匹配。

   * **问答系统**: 理解用户提问的核心含义并生成精准答案。

   * **文本聚类与分类**: 根据嵌入向量的分布，聚类相似语义的文本。

通过文本嵌入，机器不仅可以理解语言表面的表达，还能更深层次地处理和分析其语义关联，使语义搜索、文本匹配等任务更为智能和高效。

***

**图像嵌入**

图像嵌入是一种将图片转化为数值向量的技术，这些向量能够表示图像中的关键特征，比如形状、颜色、纹理和空间层次。通过这种方式，机器可以理解图像的核心内容，并以此完成分类、检索和相似性比较等任务。

举个例子，当你将一张猫的图片输入模型时，模型会分析图片中的视觉特征，比如猫耳朵的形状、毛发的纹理等。最后，这些特征会被压缩为一个高维向量，这个向量就浓缩了图片的核心信息，既能让模型识别这是猫的图片，也能与其他图像进行对比，区分它与狗或其他动物的差异。

图像嵌入有很多应用场景。比如，在图像分类中，模型可以根据嵌入向量给图片打标签，识别出它是一只猫还是一辆车。在相似性比较中，嵌入向量可以用来衡量两张图片的相似程度，常见于推荐系统中，比如推荐风格相似的照片。还有图像检索，用户上传一张图片后，系统通过嵌入向量找到数据库中最相似的图片，像以图搜图这样的功能。

实现图像嵌入通常依赖卷积神经网络（CNN），比如 ResNet 或 EfficientNet 这样的模型。这些模型经过大量数据的训练，能够提取图像的高层次特征。此外，随着技术的进步，像 Vision Transformer 这样的新模型也被用于更复杂的图像理解任务。

通过图像嵌入技术，机器能够从简单的像素点处理，进化到真正理解图像内容，这也是现代计算机视觉任务的核心方法之一。

***

**动手实践**

以下是如何使用不同嵌入方法的示例代码，帮助你快速生成文本和图像的嵌入向量。

1. OpenAIEmbedding

用于生成文本嵌入，基于 OpenAI 的模型(需要OPENAI\_API\_KEY)。

```python
from camel.embeddings import OpenAIEmbedding
from camel.types import EmbeddingModelType

# 初始化 OpenAI 嵌入模型
openai_embedding = OpenAIEmbedding(model_type=EmbeddingModelType.TEXT_EMBEDDING_3_SMALL)

# 为一组文本生成嵌入向量
embeddings = openai_embedding.embed_list(["Hello, world!", "Another example"])
```

* OpenAICompatibleEmbedding

```python
from camel.memories.blocks.vectordb_block import VectorDBBlock
from camel.memories.records import MemoryRecord
from camel.messages import BaseMessage
from camel.embeddings import SentenceTransformerEncoder,OpenAICompatibleEmbedding
from camel.types import OpenAIBackendRole
from camel.storages.vectordb_storages import QdrantStorage

from dotenv import load_dotenv
import os

load_dotenv()

embedding = OpenAICompatibleEmbedding(
    model_type="text-embedding-v3",
    url= 'https://dashscope.aliyuncs.com/compatible-mode/v1',
    api_key=os.getenv("QWEN_API_KEY")
    )

#使用OpenAICompatibleEmbedding时 需要先调用 embed_list 来确定输出维度
_ = embedding.embed_list(["测试文本"])


vector_db_block = VectorDBBlock(embedding=embedding,storage=(QdrantStorage(vector_dim=1024)))
```

* MistralEmbedding

基于 Mistral 模型的嵌入方法(需要MISTRAL\_API\_KEY)。

```python
from camel.embeddings import MistralEmbedding
from camel.types import EmbeddingModelType

# 初始化 Mistral 嵌入模型
mistral_embedding = MistralEmbedding(model_type=EmbeddingModelType.MISTRAL_EMBED)

# 为一组文本生成嵌入向量
embeddings = mistral_embedding.embed_list(["Hello, world!", "Another example"])
```

* SentenceTransformerEncoder

基于 Sentence Transformer 的文本嵌入方法，适用于高效语义表示(使用本地embedding模型，如果没有会自动下载)。

```python
from camel.embeddings import SentenceTransformerEncoder

# 初始化 Sentence Transformer 编码器
sentence_encoder = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')

# 为一组文本生成嵌入向量
embeddings = sentence_encoder.embed_list(["Hello, world!", "Another example"])
```

* VisionLanguageEmbedding

VisionLanguageEmbedding 是一个基于多模态模型（如 CLIP）的嵌入生成类，能够同时处理图像和文本输入，生成对应的嵌入向量。，默认使用本地的openai/clip-vit-base-patch32模型（如果没有会自动下载）。

```python
from camel.embeddings import VisionLanguageEmbedding
from PIL import Image
import requests

# 初始化视觉语言嵌入模型
vlm_embedding = VisionLanguageEmbedding()

# 下载测试图像
url = "http://../images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)
test_../images = [image, image]

# 为一组图像生成嵌入向量
embeddings = vlm_embedding.embed_list(test_../images)
```

```python
print(embeddings)
>>>
[[-0.10570450872182846, 0.13790780305862427, -0.29611435532569885, 0.021248599514365196, -0.06407000869512558, -0.16861875355243683, -0.13514314591884613, -0.0024490721989423037, ........... 0.07368569821119308, -0.22815512120723724, 0.1349477916955948, -0.44909897446632385, 0.12776629626750946, 0.8668186664581299, -0.014579405076801777, 0.2563166916370392]]
```

### 4.1.4 Storages

**基本概念**

Storage模块在CAMEL框架中负责数据的存储与管理，是一个功能全面的框架，提供了统一的接口和数据结构，支持键值存储和向量存储等多种类型的数据存储机制。通过抽象基类与具体实现的结合，Storage模块能够高效地处理数据的读取、写入和检索操作，为RAG应用的实现提供了坚实的基础。

***

**键值存储**

**`BaseKeyValueStorage`**

**目的**:
&#x20;作为创建各种键值存储系统的基础抽象类。

**功能**:

* 标准化数据记录的保存、加载和清除操作。

* 主要通过 Python 字典进行接口交互。

**应用场景**:

* JSON 文件存储

* NoSQL 数据库（如 MongoDB 和 Redis）

* Python 内存中的字典存储

***

**`InMemoryKeyValueStorage`**

**描述**:
&#x20;基于 `BaseKeyValueStorage` 的具体实现，使用内存中的列表存储数据。

**特点**:

* 适用于临时存储，数据为易失性，程序终止后即丢失。

**功能**:

* 实现了在内存中保存、加载和清除记录的方法。

* 非常适合开发和测试场景，无需持久化存储需求。



**向量存储**

向量存储（Vector Store）用于存储高维度的向量数据，如文本或图像的嵌入表示。它支持高效的相似度计算和最近邻搜索，是RAG应用中检索相关信息的核心组件。向量存储的特点包括：

* **高性能**：支持大规模数据的快速检索

* **可扩展性**：适应不同规模的数据量

* **灵活性**：支持多种相似度度量方式



**`BaseVectorStorage`**

**目的**:
设计为扩展特定向量存储实现的抽象基类。

**特点**:

* 支持多种操作，如添加、删除向量，查询相似向量，以及维护向量数据库的状态。

* 提供灵活性，可指定向量维度、集合名称、距离度量等参数。

**功能**:

* 为构建多样化的向量存储解决方案提供基础架构。

**`MilvusStorage`**

**描述**:
基于 `BaseVectorStorage` 的具体实现，专为与 Milvus 交互而设计的存储方案。

**特点**:

* 针对 Milvus（一个云原生向量搜索引擎）进行优化，支持高效的大规模向量检索和管理操作。

Reference: [Milvus](https://milvus.io/docs/overview.md/)



**`QdrantStorage`**

**描述**:
基于 `BaseVectorStorage` 的具体实现，专为与 Qdrant 交互而设计。

**特点**:

* 针对 Qdrant 向量搜索引擎进行优化。

* 提供高效的向量存储、管理和查询功能，支持大规模近似最近邻（ANN）搜索。

**功能**:

* 实现向量的添加、删除、相似度查询等核心操作。

* 支持自定义向量维度、集合名称、距离度量（如欧几里得距离、余弦相似度等）。

* 与 Qdrant 的 API 无缝集成，适用于高性能向量搜索场景。

**适用场景**:

* 推荐系统、自然语言处理（NLP）嵌入查询、多媒体检索（图像、音频、视频）等需要高效向量搜索的应用场景。

Reference: [Qdrant](https://qdrant.tech/)

***

&#x20;**图存储**

**`BaseGraphStorage`**

**目的**:
&#x20;设计为扩展特定图存储实现的抽象基类。

**特点**:

* 支持多种操作，包括：&#x20;

  * `get_client`: 获取图存储的客户端连接。

  * `get_schema`: 获取当前的图存储模式信息。

  * `get_structured_schema`: 获取结构化的模式表示。

  * `refresh_schema`: 刷新图存储的模式。

  * `add_triplet`: 添加三元组（节点及边的表示）。

  * `delete_triplet`: 删除三元组。

  * `query`: 执行图查询操作。

**功能**:

* 为各种图存储解决方案提供基础架构，便于构建定制化图存储实现。

**`NebulaGraph`**

**描述**:
&#x20;基于 `BaseGraphStorage` 的具体实现，专为与 NebulaGraph 交互而设计。

**特点**:

* 面向 NebulaGraph 的优化实现，支持其分布式、高扩展性及高速图数据操作的特性。

* 提供了对 NebulaGraph API 的无缝集成，用于高效处理图形数据的存储与查询。

**功能**:

* 实现了 `BaseGraphStorage` 的所有核心方法，支持快速执行分布式图数据的增删查改操作。

* 支持复杂图查询语句，用于大规模图数据的结构化分析和推理。

**适用场景**:

* 推荐系统、知识图谱、社交网络分析、路径优化及大规模图数据挖掘等需要高性能图存储和查询的场景。

Reference: [NebulaGraph](https://www.nebula-graph.io/)



**`Neo4jGraph`**

**描述**:
&#x20;基于 `BaseGraphStorage` 的具体实现，专为与 Neo4j 交互而设计，Neo4j 是业内最受信赖的图数据库之一。

**特点**:

* 面向 Neo4j 的优化实现，充分利用其强大的关系建模能力和高效的图查询功能。

* 支持复杂的图形操作和查询语句，提供强大的可视化和分析功能。

**功能**:

* 实现 `BaseGraphStorage` 的所有核心方法，包括：&#x20;

  * `get_client`: 获取连接到 Neo4j 的客户端实例。

  * `get_schema` 和 `refresh_schema`: 管理 Neo4j 图数据库的模式。

  * `add_triplet` 和 `delete_triplet`: 实现节点和关系的添加与删除。

  * `query`: 执行基于 Cypher 的图查询操作。

**适用场景**:

* 知识图谱、社交网络分析、推荐系统、诈骗检测、供应链管理及其他需要强关系建模的应用场景。

**优势**:

* 凭借 Neo4j 的成熟生态系统和广泛支持，`Neo4jGraph` 提供了一种稳定、高性能的解决方案，用于高效存储和处理复杂的图数据。

Reference: [Neo4jGraph](https://neo4j.com/)

***

**动手实践**

这里&#x4EE5;**`QdrantStorage`**&#x4E3A;例：

```python
from camel.storages import QdrantStorage, VectorDBQuery, VectorRecord

# Create an instance of QdrantStorage with dimension = 4
qdrant_storage = QdrantStorage(vector_dim=4, collection_name="my_collection")

# Add two vector records
qdrant_storage.add([VectorRecord(
            vector=[-0.1, 0.1, -0.1, 0.1],
            payload={'key1': 'value1'},
        ),
        VectorRecord(
            vector=[-0.1, 0.1, 0.1, 0.1],
            payload={'key2': 'value2'},
        ),])

# Query similar vectors
query_results = qdrant_storage.query(VectorDBQuery(query_vector=[0.1, 0.2, 0.1, 0.1], top_k=1))
for result in query_results:
    print(result.record.payload, result.similarity)

# Clear all vectors
qdrant_storage.clear()

>>> 
{'key2': 'value2'} 0.5669467095138407
```

这里计算出的结果是向量之间的余弦距离（默认），CAMEL提供了3种计算距离的方式，可在`QdrantStorage`初始化的时候指定*distance*参数来选择：

```plain&#x20;text
distance_map = {
    VectorDistance.DOT: Distance.DOT,        # 点积距离
    VectorDistance.COSINE: Distance.COSINE,  # 余弦距离 
    VectorDistance.EUCLIDEAN: Distance.EUCLID # 欧氏距离
}
```

***

### 4.1.5 Retrievers

**基本概念**

Retrievers 模块可以理解为一个搜索引擎，专门用于在大量文本中高效查找特定信息。它的功能就像一位熟练的图书管理员，帮助你快速找到需要的主题或关键词，无论是基于语义还是关键字。

Retrievers 模块支持两种主要的检索方式：向量检索和关键词检索。

向量检索器（Vector Retriever）基于向量表示技术，将文本、图像等数据转化为高维向量，通过嵌入模型生成数学表示并存储在向量存储系统中。当用户输入查询时，嵌入模型会将其转换为向量，在存储系统中寻找最接近的匹配向量。这种方式擅长处理语义搜索，能够理解自然语言的模糊关系，常应用于推荐系统、语义查询和跨模态搜索等场景。

关键词检索器（Keyword Retriever）则更加直接，通过对文档进行预处理（如分词、建立关键词索引），解析用户的查询关键词并匹配相应的文档内容。它依赖于关键词的精确匹配，适合快速查找特定术语或短语。

向量检索器偏向语义层面的理解，适合模糊查询和深度语义挖掘；而关键词检索器则注重精确性，适合快速直接的检索需求。两者结合使用，可以在不同场景中提供高效的解决方案，是知识管理、问答系统和检索增强生成（RAG）任务的重要工具。

***

**动手实践**

1. 向量检索

初始化 VectorRetriever

我们首先需要初始化 `VectorRetriever`。可以选择传入一个嵌入模型，如果不提供嵌入模型，默认会使用 `OpenAIEmbedding`。

```python
from camel.embeddings import SentenceTransformerEncoder
from camel.retrievers import VectorRetriever

embedding_model=SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')

```

嵌入并存储数据

在执行检索之前，需要准备数据并将其存储在向量存储中。`process` 方法会处理输入内容（可以是文件或 URL），将内容划分为小块，并将这些小块的嵌入存储在指定的向量存储中。

```python
# 指定内容来源路径，可以是文件路径或 URL
content_input_path = "https://www.camel-ai.org/"

# 创建或初始化向量存储（例如 QdrantStorage）
from camel.storages.vectordb_storages import QdrantStorage

vector_storage = QdrantStorage(
    vector_dim=embedding_model.get_output_dim(),  # 嵌入向量的维度
    collection_name="my first collection",          # 向量存储的集合名称
    path="storage_customized_run",                  # 向量存储的位置
)
# 初始化 VectorRetriever
vr = VectorRetriever(embedding_model=embedding_model,storage=vector_storage)
# 将内容嵌入并存储到向量存储中
vr.process(content_input_path, chunk_type="chunk_by_title")
```

执行查询

将数据存储后，可以通过查询字符串来检索相关信息。`query` 方法会根据输入的查询语句，从存储中检索最匹配的信息。

```python
# 指定查询字符串
query = "What is CAMEL"

# 执行查询并检索结果
results = vr.query(query)

# 打印检索结果
print(results)
```

**示例输出**：

```plain&#x20;text
[{'similarity score': '0.8388913333364109', 'content path': 'https://www.camel-ai.org/', 'metadata': {'emphasized_text_contents': ['1 Customize agents'], 'emphasized_text_tags': ['b'], 'filetype': 'text/html', 'languages': ['eng'], 'link_texts': ['Get Started', 'Join Community'], 'link_urls': ['https://github.com/camel-ai', 'http://discord.camel-ai.org/'], 'url': 'https://www.camel-ai.org/'}, 'extra_info': {}, 'text': 'Build Multi-Agent Systems for Data Generation\n\nCAMEL-AI.org is the 1st LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.\n\nGet StartedJoin Community\n\n1 Customize agents\n\nCustomizable agents are the fundamental entities of the CAMEL architecture. CAMEL empowers you to customize agents using our modular components for specific tasks.'}]
```

* 自动化检索

**AutoRetriever** 方法进一步简化了检索流程，它自动处理嵌入、存储数据以及执行查询的任务，非常适合需要处理多个内容输入路径的场景。

```python
from camel.retrievers import AutoRetriever
from camel.types import StorageType
from camel.embeddings import SentenceTransformerEncoder

embedding_model=SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')

# 初始化 AutoRetriever
ar = AutoRetriever(
    vector_storage_local_path="retrievers",  # 向量存储本地路径
    storage_type=StorageType.QDRANT,               # 使用 Qdrant 作为存储类型
    embedding_model=embedding_model
)

# 使用 Auto Retriever 执行嵌入、存储和查询
retrieved_info = ar.run_vector_retriever(
    contents=[
        "https://www.camel-ai.org/",  # 示例 URL
    ],
    query="What is CAMEL-AI",         # 查询字符串
    return_detailed_info=True         # 是否返回详细信息，包括元数据
)

# 打印检索结果
print(retrieved_info)
```

**输出示例**：

```plain&#x20;text
{'Original Query': 'What is CAMEL-AI', 'Retrieved Context': [{'similarity score': '0.8677001653976963', 'content path': 'https://www.camel-ai.org/', 'metadata': {'emphasized_text_contents': ['1 Customize agents'], 'emphasized_text_tags': ['b'], 'filetype': 'text/html', 'languages': ['eng'], 'link_texts': ['Get Started', 'Join Community'], 'link_urls': ['https://github.com/camel-ai', 'http://discord.camel-ai.org/'], 'url': 'https://www.camel-ai.org/'}, 'extra_info': {}, 'text': 'Build Multi-Agent Systems for Data Generation\n\nCAMEL-AI.org is the 1st LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.\n\nGet StartedJoin Community\n\n1 Customize agents\n\nCustomizable agents are the fundamental entities of the CAMEL architecture. CAMEL empowers you to customize agents using our modular components for specific tasks.'}]}
```

**内容输入路径**：`contents` 可以是文件路径或 URL，支持多个输入。**查询字符串**：`query` 定义了检索目标，AutoRetriever 将根据该字符串搜索相关内容。**返回详细信息**：设置 `return_detailed_info=True` 可返回包括元数据在内的详细检索信息。

***